{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the [ComfyUI](https://github.com/comfyanonymous/ComfyUI) repo and install the requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bbbbbbbbbb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!git clone -q https://github.com/comfyanonymous/ComfyUI\n",
        "%pip install -q xformers!=0.0.18 -r /content/ComfyUI/requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some Helpful Custom Nodes\n",
        "!git clone -q https://github.com/ltdrdata/ComfyUI-Manager /content/ComfyUI/custom_nodes/comfyui-manager\n",
        "\n",
        "!git clone -q https://github.com/ClownsharkBatwing/RES4LYF.git /content/ComfyUI/custom_nodes/RES4LYF\n",
        "!git clone -q https://github.com/rgthree/rgthree-comfy.git /content/ComfyUI/custom_nodes/rgthree-comfy\n",
        "!git clone -q https://github.com/yolain/ComfyUI-Easy-Use.git /content/ComfyUI/custom_nodes/ComfyUI-Easy-Use"
      ],
      "metadata": {
        "id": "0a9tsc6ym4F6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download the vae and dual text encoder needed for FLUX - (Compulsory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb9xz1ViENoO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!wget -q --show-progress https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors -P /content/ComfyUI/models/text_encoders/\n",
        "!wget -q --show-progress https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors -P /content/ComfyUI/models/text_encoders/\n",
        "!wget -q --show-progress https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/ae.safetensors -P /content/ComfyUI/models/vae/\n",
        "\n",
        "# 8-step distilled lora for fast inference on dev models\n",
        "# !wget -q --show-progress https://huggingface.co/alimama-creative/FLUX.1-Turbo-Alpha/resolve/main/diffusion_pytorch_model.safetensors -P /content/ComfyUI/models/loras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWglWy21uVpP"
      },
      "source": [
        "\n",
        "The **FP8 version** runs smoothly on the free tier (without LoRA), but if you want to use it with a LoRA, it requires more resources than the free Colab tier provides.  \n",
        "In that case, you can opt for the [gguf](https://huggingface.co/collections/QuantStack/flux-ggufs-68264cfc663d50c418940b30) quantized versions or the [Nunchaku](https://huggingface.co/nunchaku-tech/models) versions instead.\n",
        "\n",
        ">**Note** : You need only one , either a gguf quantized model (under 10GB) or the Nunchanku model\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 1 : fp8 quantized - from [Comfy-Org](https://huggingface.co/Comfy-Org/flux1-dev/tree/main)"
      ],
      "metadata": {
        "id": "zl70QUxzr5TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fp8 - needs more than free tier\n",
        "# !wget -q --show-progress https://huggingface.co/Comfy-Org/flux1-dev/resolve/main/flux1-dev-fp8.safetensors -P /content/ComfyUI/models/checkpoints"
      ],
      "metadata": {
        "id": "5JcA4RTtr0g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 2 : [**gguf**](https://huggingface.co/city96/FLUX.1-dev-gguf) models.  "
      ],
      "metadata": {
        "id": "fcYI0H2QnITb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Git clone the [ComfyUI-GGUF](https://github.com/city96/ComfyUI-GGUF) repo and follow the instructions."
      ],
      "metadata": {
        "id": "rBW-zqXfzsYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dvla7XiuVpN"
      },
      "outputs": [],
      "source": [
        "# %pip install --upgrade gguf\n",
        "# !rm -rf ./custom_nodes/ComfyUI-GGUF\n",
        "# !git clone https://github.com/city96/ComfyUI-GGUF /content/ComfyUI/custom_nodes/ComfyUI-GGUF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojrmju_XuVpQ"
      },
      "outputs": [],
      "source": [
        "# Download the one you need\n",
        "\n",
        "# flux1-dev\n",
        "# !wget -q --show-progress https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q6_K.gguf -P /content/ComfyUI/models/unet\n",
        "\n",
        "# flux1-kontext-dev\n",
        "# !wget -q --show-progress https://huggingface.co/QuantStack/FLUX.1-Kontext-dev-GGUF/resolve/main/flux1-kontext-dev-Q6_K.gguf -P /content/ComfyUI/models/unet\n",
        "\n",
        "# flux1-krea-dev\n",
        "# !wget -q --show-progress https://huggingface.co/QuantStack/FLUX.1-Krea-dev-GGUF/resolve/main/flux1-krea-dev-Q6_K.gguf -P /content/ComfyUI/models/unet\n",
        "\n",
        "# flux1-schnell\n",
        "# !wget -q --show-progress https://huggingface.co/city96/FLUX.1-schnell-gguf/resolve/main/flux1-schnell-Q6_K.gguf -P /content/ComfyUI/models/unet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 3 : [**Nunchaku**](https://nunchaku.tech/docs/ComfyUI-nunchaku/workflows/t2i.html#nunchaku-flux-1-dev-json) models - recommended"
      ],
      "metadata": {
        "id": "yDlSKb2rprjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "id": "GkNw42U8_F8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -q https://github.com/mit-han-lab/ComfyUI-nunchaku /content/ComfyUI/custom_nodes/nunchaku_nodes\n",
        "!pip install -q https://github.com/nunchaku-tech/nunchaku/releases/download/v1.0.0/nunchaku-1.0.0+torch2.8-cp312-cp312-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "Kxd_5jqxp7Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flux1-dev\n",
        "!wget -q --show-progress https://huggingface.co/nunchaku-tech/nunchaku-flux.1-dev/resolve/main/svdq-int4_r32-flux.1-dev.safetensors -P /content/ComfyUI/models/diffusion_models\n",
        "\n",
        "#flux1-krea-dev\n",
        "# !wget -q --show-progress https://huggingface.co/nunchaku-tech/nunchaku-flux.1-krea-dev/resolve/main/svdq-int4_r32-flux.1-krea-dev.safetensors -P /content/ComfyUI/models/diffusion_models\n",
        "\n",
        "#flux1-schnell\n",
        "# !wget -q --show-progress https://huggingface.co/nunchaku-tech/nunchaku-flux.1-schnell/resolve/main/svdq-int4_r32-flux.1-schnell.safetensors -P /content/ComfyUI/models/diffusion_models\n",
        "\n",
        "#flux1-kontext-dev\n",
        "# !wget -q --show-progress https://huggingface.co/nunchaku-tech/nunchaku-flux.1-kontext-dev/resolve/main/svdq-int4_r32-flux.1-kontext-dev.safetensors -P /content/ComfyUI/models/diffusion_models"
      ],
      "metadata": {
        "id": "WOTtjTUORfQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run ComfyUI with ngrok"
      ],
      "metadata": {
        "id": "8XPOPExF_tly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import subprocess, socket, time\n",
        "from google.colab import userdata\n",
        "\n",
        "NGROK_TOKEN = userdata.get(\"NGROK_TOKEN\")\n",
        "\n",
        "# Set ngrok token\n",
        "!ngrok config add-authtoken $NGROK_TOKEN\n",
        "\n",
        "# --- Auto-fix Nunchaku LoRA loader crash + remove duplicate folder (Colab-safe) ---\n",
        "import os, shutil, time, subprocess, glob\n",
        "\n",
        "CUSTOM_NODES = \"/content/ComfyUI/custom_nodes\"\n",
        "BACKUPS_DIR  = \"/content/custom_nodes_backups\"\n",
        "os.makedirs(BACKUPS_DIR, exist_ok=True)\n",
        "\n",
        "# 1) Remove duplicate old nunchaku folder if present (prevents conflicts)\n",
        "old_folder = os.path.join(CUSTOM_NODES, \"nunchaku_nodes\")\n",
        "if os.path.isdir(old_folder):\n",
        "    stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    dest = os.path.join(BACKUPS_DIR, f\"nunchaku_nodes_{stamp}\")\n",
        "    print(f\"üßπ Moving duplicate folder out of custom_nodes: {old_folder} -> {dest}\")\n",
        "    shutil.move(old_folder, dest)\n",
        "\n",
        "# 2) Patch deepcopy(model) -> model.clone() in known files\n",
        "targets = [\n",
        "    \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/lora/flux.py\",\n",
        "    \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/models/pulid.py\",\n",
        "]\n",
        "\n",
        "for f in targets:\n",
        "    if os.path.isfile(f):\n",
        "        # backup once per runtime\n",
        "        bak = f + \".bak\"\n",
        "        if not os.path.isfile(bak):\n",
        "            shutil.copy2(f, bak)\n",
        "\n",
        "        with open(f, \"r\", encoding=\"utf-8\") as r:\n",
        "            txt = r.read()\n",
        "\n",
        "        if \"copy.deepcopy(model)\" in txt:\n",
        "            txt2 = txt.replace(\"copy.deepcopy(model)\", \"model.clone()\")\n",
        "            with open(f, \"w\", encoding=\"utf-8\") as w:\n",
        "                w.write(txt2)\n",
        "            print(f\"‚úÖ Patched: {f}\")\n",
        "        else:\n",
        "            print(f\"‚ÑπÔ∏è No deepcopy(model) found in: {f}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Missing file (skip): {f}\")\n",
        "\n",
        "print(\"‚úÖ Pre-launch fixes complete.\\n\")\n",
        "# --- End auto-fix block ---\n",
        "\n",
        "# Start ComfyUI in background\n",
        "subprocess.Popen([\"python\", \"/content/ComfyUI/main.py\", \"--dont-print-server\"])\n",
        "\n",
        "# Wait until port is open\n",
        "port = 8188\n",
        "while True:\n",
        "    try:\n",
        "        sock = socket.create_connection((\"127.0.0.1\", port), timeout=2)\n",
        "        sock.close()\n",
        "        print(\"‚úÖ ComfyUI server is running on port\", port)\n",
        "        break\n",
        "    except OSError:\n",
        "        print(\"‚è≥ Waiting for ComfyUI to start...\")\n",
        "        time.sleep(2)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8188, bind_tls=True)\n",
        "print(\"üåê Public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "MTI7AYf1_ExB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !npm install -g localtunnel"
      ],
      "metadata": {
        "id": "47QdZgYl4EzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import subprocess\n",
        "# import threading\n",
        "# import time\n",
        "# import socket\n",
        "# import urllib.request\n",
        "# import sys\n",
        "\n",
        "# def wait_for_port(port):\n",
        "#     while True:\n",
        "#         time.sleep(0.5)\n",
        "#         sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "#         if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "#             sock.close()\n",
        "#             break\n",
        "#         sock.close()\n",
        "\n",
        "#     print(\"\\nComfyUI finished loading, launching localtunnel...\\n\")\n",
        "#     print(\"Your public IP is:\",\n",
        "#           urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip())\n",
        "\n",
        "#     p = subprocess.Popen([\"lt\", \"--port\", str(port)], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "#     for line in iter(p.stdout.readline, ''):\n",
        "#         sys.stdout.write(line)\n",
        "#         sys.stdout.flush()\n",
        "\n",
        "# threading.Thread(target=wait_for_port, args=(8188,), daemon=True).start()\n",
        "\n",
        "# subprocess.run([\"python\", \"/content/ComfyUI/main.py\"])\n"
      ],
      "metadata": {
        "id": "l368kqI3-Bm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/ComfyUI/models/loras/cd_r1-e4.safetensors \"https://huggingface.co/iFreDDyz/cd-lora1/resolve/main/cd_r1-e4.safetensors\"\n",
        "!wget -O /content/ComfyUI/models/loras/cd_r1-e5.safetensors \"https://huggingface.co/iFreDDyz/cd-lora1/resolve/main/cd_r1-e5.safetensors\"\n",
        "!wget -O /content/ComfyUI/models/loras/cd_r1-e6.safetensors \"https://huggingface.co/iFreDDyz/cd-lora1/resolve/main/cd_r1-e6.safetensors\"\n",
        "!wget -O /content/ComfyUI/models/loras/cd_r1-e7.safetensors \"https://huggingface.co/iFreDDyz/cd-lora1/resolve/main/cd_r1-e7.safetensors\"\n",
        "!wget -O /content/ComfyUI/models/loras/cd_r1-e8.safetensors \"https://huggingface.co/iFreDDyz/cd-lora1/resolve/main/cd_r1-e8.safetensors\"\n",
        "!wget -O /content/ComfyUI/models/loras/cd_r1-e9.safetensors \"https://huggingface.co/iFreDDyz/cd-lora1/resolve/main/cd_r1-e9.safetensors\"\n",
        "!wget -O /content/ComfyUI/models/loras/cd_r1-e10.safetensors \"https://huggingface.co/iFreDDyz/cd-lora1/resolve/main/cd_r1-e10.safetensors\""
      ],
      "metadata": {
        "id": "TJ2u5eRWgDd_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gggggggggg"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}